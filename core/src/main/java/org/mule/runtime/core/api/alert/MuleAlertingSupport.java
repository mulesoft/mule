/*
 * Copyright 2023 Salesforce, Inc. All rights reserved.
 * The software in this package is published under the terms of the CPAL v1.0
 * license, a copy of which has been included with this distribution in the
 * LICENSE.txt file.
 */
package org.mule.runtime.core.api.alert;

import org.mule.api.annotation.Experimental;
import org.mule.api.annotation.NoImplement;
import org.mule.runtime.api.alert.AlertingSupport;
import org.mule.runtime.api.alert.TimedDataAggregation;

import java.util.Map;
import java.util.function.BiFunction;
import java.util.function.Supplier;

@NoImplement
@Experimental
public interface MuleAlertingSupport extends AlertingSupport {

  public final class AlertNames {

    /**
     * MULE:UNKNOWN errors are generated by the runtime and unhandled. If such an error is raised or visible in the app log, it is
     * a bug in the Mule Runtime.
     * <p>
     * Additional data in alerts:
     * <ul>
     * <li>Type and message of the actual exception</li>
     * </ul>
     */
    public static final String ALERT_MULE_UNKNOWN_ERROR_RAISED = "MULE_UNKNOWN_ERROR_RAISED";

    /**
     * A stream that is GCd when it hasn't been completely consumed may provoke leaks on certain conditions (the most common one
     * is connections from a db connection pool that remain taken until the data is fully read).
     * <p>
     * Additional data in alerts:
     * <ul>
     * <li>Location of the component that generated the stream</li>
     * </ul>
     */
    public static final String ALERT_NOT_CONSUMED_STREAM_BUSTED = "NOT_CONSUMED_STREAM_BUSTED";

    /**
     * Backpressure is the mechanism by which incoming events in excess of current capacity are rejected. This could happen
     * because of a spike of incoming events or a longer than usual processing time of the flows. A common smell in this case is
     * when backpressure is triggered for systems that have capacity cpu and memory wise.
     * <p>
     * Additional data in alerts:
     * <ul>
     * <li>Reason for backpressure and the name of the flow in which it occurred</li>
     * </ul>
     */
    public static final String ALERT_BACKPRESSURE_TRIGGERED = "BACKPRESSURE_TRIGGERED";

    /**
     * A discarded event is one that was explicitly filtered by a component in a flow. This effectively cuts the processing of
     * such event, causing the execution to hang.
     * <p>
     * Additional data in alerts:
     * <ul>
     * <li>The correlation if of the event that was discarded</li>
     * </ul>
     */
    public static final String ALERT_REACTOR_DISCARDED_EVENT = "REACTOR_DISCARDED_EVENT";

    /**
     * A dropped event is one that was not properly passed to the following component in a flow through a reactor chain, and so is
     * not completed. Its symptom is that the event is "hanged".
     * <p>
     * Additional data in alerts:
     * <ul>
     * <li>The correlation if of the event that was discarded</li>
     * </ul>
     */
    public static final String ALERT_REACTOR_DROPPED_EVENT = "REACTOR_DROPPED_EVENT";

    /**
     * A dropped error is one that was not properly passed to the corresponding error handler in a flow through a reactor chain,
     * and so is not completed. Its symptom is that the event is "hanged" when an error occurs.
     * <p>
     * Additional data in alerts:
     * <ul>
     * <li>Type and message of the dropped exception</li>
     * </ul>
     */
    public static final String ALERT_REACTOR_DROPPED_ERROR = "REACTOR_DROPPED_ERROR";

    /**
     * Additional data in alerts:
     * <ul>
     * <li>Unique name (includes the config name) of the connection for which recovery failed.</li>
     * </ul>
     */
    public static final String ALERT_XA_RECOVERY_START_ERROR = "XA_RECOVERY_START_ERROR";

    private AlertNames() {
      // Nothing to do
    }
  }


  /**
   * Counts each alert for the times it happened in the last 1, 5 and 15 minutes.
   * <p>
   * The time intervals are the same as reported by *nix load average, so that data can be correlated.
   *
   * @return the count aggregation for each alert.
   */
  Map<String, TimedDataAggregation<Integer>> alertsCountAggregation();

  /**
   * Aggregates each alert using the provided parameters for the times it happened in the last 1, 5 and 15 minutes.
   * <p>
   * The time intervals are the same as reported by *nix load average, so that data can be correlated.
   *
   * @param baseIntervalAggregationSupplier supplier of the base object on which aggregators will be done.
   * @param accumulator                     the function to apply on the updated base with each item being aggregated.
   * @return the count aggregation for each alert.
   */
  <A> Map<String, TimedDataAggregation<A>> alertsAggregation(Supplier<A> baseIntervalAggregationSupplier,
                                                             BiFunction<A, Object, A> accumulator);

}
